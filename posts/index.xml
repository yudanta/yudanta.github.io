<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Ydn&#39;s personal blog.</title>
    <link>https://yudanta.github.io/posts/</link>
    <description>Recent content in Posts on Ydn&#39;s personal blog.</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 26 Oct 2020 23:23:57 +0700</lastBuildDate>
    
	<atom:link href="https://yudanta.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Train an Indonesian NER From a Blank SpaCy Model</title>
      <link>https://yudanta.github.io/posts/train-an-indonesian-ner-from-a-blank-spacy-model/</link>
      <pubDate>Mon, 26 Oct 2020 23:23:57 +0700</pubDate>
      
      <guid>https://yudanta.github.io/posts/train-an-indonesian-ner-from-a-blank-spacy-model/</guid>
      <description>So, how we train a Named Entity Recognition model in SpaCy using our own dataset? long story short, though the title is in English, but this time I will write the story in Indonesian, since the model is an Indonesian Named Entity Recognition.
Jadi&amp;hellip; bagi yang ingin bikin model untuk keperluan &amp;ldquo;sequence-tagging&amp;rdquo; seperti Ekstraksi Entitas dan Pengenalan Entitas, maka biar tidak pusing atau pusing dengan bikin model pakai stack LSTM atau LSTM+CRF seperti kebanyakan yang ada di tutorial-tutorial itu, apalagi pakai embedding kaya word2vec dan glove dan bert fang femes itu kan overkill&amp;hellip; dan tentunya bakal lama, ya to ya?</description>
    </item>
    
    <item>
      <title>Series 3 Exporting LSTM Gender Classification and Serving With Flask</title>
      <link>https://yudanta.github.io/posts/series-3-exporting-lstm-gender-classification-and-serving-with-flask/</link>
      <pubDate>Mon, 12 Oct 2020 22:38:16 +0700</pubDate>
      
      <guid>https://yudanta.github.io/posts/series-3-exporting-lstm-gender-classification-and-serving-with-flask/</guid>
      <description>Hello again, so this is the last part of our series about developing gender classification model with deep learning approach. in the previous post we know already how to deploy our model directly into TFServing and run the service inside a docker container, if you did not read the previous series please follow this links:
 Training LSTM Model for gender classification Serving model with Tensorflow Serving  For the last part of our series, we will learn and deploy our trained model with Flask, so it will attached to your web application built with flask.</description>
    </item>
    
    <item>
      <title>Series 2 Exporting LSTM Gender Classification and Serving With Tensorflowserving</title>
      <link>https://yudanta.github.io/posts/series-2-exporting-lstm-gender-classification-and-serving-with-tensorflowserving/</link>
      <pubDate>Thu, 01 Oct 2020 14:17:47 +0700</pubDate>
      
      <guid>https://yudanta.github.io/posts/series-2-exporting-lstm-gender-classification-and-serving-with-tensorflowserving/</guid>
      <description>So this is the second part of the series, in the previous part we successfully train our model and test the model directly from trained model instance. in this part we will export the model and serve the model with tensorflow serving so it can be accessed with REST api or gRPC endpoints, in short you can serve your model like in production, so others can performing request to ask a gender prediction to your model.</description>
    </item>
    
    <item>
      <title>Series 1 LSTM Gender Classification Tensorflow</title>
      <link>https://yudanta.github.io/posts/series-1-lstm-gender-classification-tensorflow/</link>
      <pubDate>Sun, 27 Sep 2020 22:36:58 +0700</pubDate>
      
      <guid>https://yudanta.github.io/posts/series-1-lstm-gender-classification-tensorflow/</guid>
      <description>Hello&amp;hellip; this post will be part of a serial posts about how we using deep learning approach for simple text classification model, starting from training the model until serving the model into &amp;ldquo;production ready&amp;rdquo; application with TensorflowServing or Flask. This series posts will be divided into 3 posts, the first one is preparing and training our simple model to recognize a gender based on name.
Lets say we want a model for our application needs to predict user&amp;rsquo;s gender based on their name, so at first we have a datasets a pair of name and gender in .</description>
    </item>
    
    <item>
      <title>Simple Asymetric Encryption With Python</title>
      <link>https://yudanta.github.io/posts/simple-asymetric-encryption-with-python/</link>
      <pubDate>Mon, 14 Sep 2020 12:55:59 +0700</pubDate>
      
      <guid>https://yudanta.github.io/posts/simple-asymetric-encryption-with-python/</guid>
      <description>So, first of all, this is just a snippet for those who courious and wants to know about asymetric encryption using private and public key to securing your data or communication. As we know, end to end encryption is very popular right now such as in your private messaging application (Whatsapp or Telegram), it is non deniable, one of our way to securing our communication in digital era.
The concept is very simmple, both parties are generating two kind of keys, one is private and one is public.</description>
    </item>
    
    <item>
      <title>Nvidia Docker and Docker Compose Enabled</title>
      <link>https://yudanta.github.io/posts/nvidia-docker-and-docker-compose-enabled/</link>
      <pubDate>Fri, 11 Jan 2019 19:20:23 +0700</pubDate>
      
      <guid>https://yudanta.github.io/posts/nvidia-docker-and-docker-compose-enabled/</guid>
      <description>Recently, I rely much on docker. Almost all of my projects already dockerised and it working flawlessly. The main reason of using docker is because it&amp;rsquo;s easy to maintain and isolated, not make your host OS dirty with tons of files and dependencies. And, since I am working closely with my coleague at the office we use docker as part of our workflow. Sharing projects, doing CI/CD and releasing updates to our Kubernetes cluster never as easy and seamless like this before.</description>
    </item>
    
    <item>
      <title>Flask Mongoengine, Multiple Databases With Alias</title>
      <link>https://yudanta.github.io/posts/flask-mongoengine-multiple-databases-with-alias/</link>
      <pubDate>Fri, 11 Jan 2019 19:19:08 +0700</pubDate>
      
      <guid>https://yudanta.github.io/posts/flask-mongoengine-multiple-databases-with-alias/</guid>
      <description>It&amp;rsquo;s common in some occasions our applications are consuming and storing data from two or more MongoDB databases, and if you are using Mongoengine as your database abstraction you are lucky enough that Mongoengine is capable to accessing multiple database without hassle, refering this documentation: http://docs.mongoengine.org/guide/connecting.html?highlight=alias#multiple-databases, we can connecting to multiple database and using alias or db_alias
Now, for accessing multiple database with Flask and Flask-Mongoengine, first define the database connection info and credentials in our flask config file config.</description>
    </item>
    
    <item>
      <title>How I Dockerize My Flask App With Pypy and Supervisord</title>
      <link>https://yudanta.github.io/posts/how-i-dockerize-my-flask-app-with-pypy-and-supervisord/</link>
      <pubDate>Wed, 19 Dec 2018 00:21:38 +0700</pubDate>
      
      <guid>https://yudanta.github.io/posts/how-i-dockerize-my-flask-app-with-pypy-and-supervisord/</guid>
      <description>There are bunch of ways how to deploy your Flask application, it can be directly with Flask&amp;rsquo;s built in http server or use UWSGI as gateway interface, with or without Nginx as your HTTP frontend. People also either run Flask application directly on their machine or as a container with docker.
In this post, I will share the way I deploy my Flask application. Lately, I prefer to use PyPy rather than using pure Python to achieve more speed processing time (thanks to its JIT Compiler), and use Gevent to handle more concurrency.</description>
    </item>
    
    <item>
      <title>The Books I Read Recently</title>
      <link>https://yudanta.github.io/posts/the-books-i-read-recently/</link>
      <pubDate>Tue, 18 Dec 2018 18:42:53 +0700</pubDate>
      
      <guid>https://yudanta.github.io/posts/the-books-i-read-recently/</guid>
      <description>To be honest, I am not kind of such a book worm nor a book enthusiast. I read books occasionaly, when I am tired in front of my computers or I want to refresh my mind for a while. At the end of this year, I want to share my thoughts related to some books which I have read during this year.
&amp;lsquo;Origin&amp;rsquo; written by Dan Brown
I read Dan Brown&amp;rsquo;s works since Digital Fortress.</description>
    </item>
    
    <item>
      <title>Hello World</title>
      <link>https://yudanta.github.io/posts/hello-world/</link>
      <pubDate>Sat, 15 Dec 2018 16:43:22 +0700</pubDate>
      
      <guid>https://yudanta.github.io/posts/hello-world/</guid>
      <description>Hello, I will keep you as my first footprint in this site
#!/usr/bin/env python  print(&amp;#39;hello-world!&amp;#39;) </description>
    </item>
    
  </channel>
</rss>
<!DOCTYPE html>
<html lang="en-us">
	<head>
    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="author" content="Yudanta">
<meta name="description" content="echo &#39;to make it immortal&#39; &gt; blog/journey_{date}.md">
<meta name="generator" content="Hugo 0.74.3" />
<title>Series 2 Exporting LSTM Gender Classification and Serving With Tensorflowserving</title>
<link rel="shortcut icon" href="https://yudanta.github.io/images/favicon.ico">
<link rel="stylesheet" href="https://yudanta.github.io/css/style.css">
<link rel="stylesheet" href="https://yudanta.github.io/css/highlight.css">



<link rel="stylesheet" href="https://yudanta.github.io/css/monosocialiconsfont.css">



<link href="https://yudanta.github.io/index.xml" rel="alternate" type="application/rss+xml" title="Ydn&#39;s personal blog." />


<meta property="og:title" content="Series 2 Exporting LSTM Gender Classification and Serving With Tensorflowserving" />
<meta property="og:description" content="So this is the second part of the series, in the previous part we successfully train our model and test the model directly from trained model instance. in this part we will export the model and serve the model with tensorflow serving so it can be accessed with REST api or gRPC endpoints, in short you can serve your model like in production, so others can performing request to ask a gender prediction to your model." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://yudanta.github.io/posts/series-2-exporting-lstm-gender-classification-and-serving-with-tensorflowserving/" />
<meta property="article:published_time" content="2020-10-01T14:17:47+07:00" />
<meta property="article:modified_time" content="2020-10-01T14:17:47+07:00" />



<meta itemprop="name" content="Series 2 Exporting LSTM Gender Classification and Serving With Tensorflowserving">
<meta itemprop="description" content="So this is the second part of the series, in the previous part we successfully train our model and test the model directly from trained model instance. in this part we will export the model and serve the model with tensorflow serving so it can be accessed with REST api or gRPC endpoints, in short you can serve your model like in production, so others can performing request to ask a gender prediction to your model.">
<meta itemprop="datePublished" content="2020-10-01T14:17:47+07:00" />
<meta itemprop="dateModified" content="2020-10-01T14:17:47+07:00" />
<meta itemprop="wordCount" content="851">



<meta itemprop="keywords" content="Tensorflow,Text Classification,NLP,LSTM," />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Series 2 Exporting LSTM Gender Classification and Serving With Tensorflowserving"/>
<meta name="twitter:description" content="So this is the second part of the series, in the previous part we successfully train our model and test the model directly from trained model instance. in this part we will export the model and serve the model with tensorflow serving so it can be accessed with REST api or gRPC endpoints, in short you can serve your model like in production, so others can performing request to ask a gender prediction to your model."/>
<meta name="twitter:site" content="@https://twitter.com/akuyudanta/"/>


    </head>
<body>
    <nav class="main-nav">
	
		<a href='https://yudanta.github.io/'> <span class="arrow">←</span>Home</a>
	

	
 		<a href='/about/'>About</a>
  	
 		<a href='/posts'>Posts</a>
  	
 		<a href='/series'>Series</a>
  	

	
		<a class="cta" href="https://yudanta.github.io/index.xml">Subscribe</a>
	
</nav>

    <section id="wrapper">
        
        
<article class="post">
    <header>
        <h1>Series 2 Exporting LSTM Gender Classification and Serving With Tensorflowserving</h1>
        <h2 class="subtitle"></h2>
        <h2 class="headline">
        October 1, 2020
        <br>
        
        
            
                <a href="https://yudanta.github.io/tags/tensorflow">Tensorflow</a>
            
                <a href="https://yudanta.github.io/tags/text-classification">Text Classification</a>
            
                <a href="https://yudanta.github.io/tags/nlp">NLP</a>
            
                <a href="https://yudanta.github.io/tags/lstm">LSTM</a>
            
        
        
        </h2>
    </header>
    <section id="post-body">
        <p>So this is the second part of the series, in the previous part we successfully train our model and test the model directly from trained model instance. in this part we will export the model and serve the model with tensorflow serving so it can be accessed with REST api or gRPC endpoints, in short you can serve your model like in production, so others can performing request to ask a gender prediction to your model.</p>
<h3 id="exporting-trained-model-for-tensorflow-serving">Exporting Trained Model for Tensorflow Serving</h3>
<p>In this section, we will use (again) docker to handle our tensorflow serving instance and serving model, but first we need to look back to our previous training notebook, we need to save our character dictionary for later prediction use. this is use to encode our sequence input to model prediction later,</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">print</span>(vocab_index)
<span style="color:#75715e">#&gt;&gt; {&#39;b&#39;: 1, &#39;w&#39;: 2, &#39;i&#39;: 3, &#39;.&#39;: 4, &#39;d&#39;: 5, &#39;r&#39;: 6, &#39;s&#39;: 7, &#39;h&#39;: 8, &#39;m&#39;: 9, &#34;&#39;&#34;: 10, &#39;f&#39;: 11, &#39;q&#39;: 12, &#39;g&#39;: 13, &#39;c&#39;: 14, &#39;l&#39;: 15, &#39;y&#39;: 16, &#39;u&#39;: 17, &#39;p&#39;: 18, &#39; &#39;: 19, &#39;t&#39;: 20, &#39;n&#39;: 21, &#39;k&#39;: 22, &#39;v&#39;: 23, &#39;o&#39;: 24, &#39;z&#39;: 25, &#39;e&#39;: 26, &#39;j&#39;: 27, &#39;a&#39;: 28}</span>

<span style="color:#75715e"># save to json file for later use</span>
<span style="color:#f92672">import</span> json
<span style="color:#66d9ef">with</span> open(<span style="color:#e6db74">&#39;char_dictionary.json&#39;</span>, <span style="color:#e6db74">&#39;w&#39;</span>) <span style="color:#66d9ef">as</span> f:
    json<span style="color:#f92672">.</span>dump(vocab_index, f)
</code></pre></div><p>okay, first we need to export our trained model for tensorflow serving, bear in mind tensorflow serving using name directory as versioning system (1, 2&hellip; etc)</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># first create lstm_gender directory for our export directory through your notebook</span>
<span style="color:#960050;background-color:#1e0010">!</span> mkdir lstm_gender
</code></pre></div><p>then export</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> os

MODEL_DIR <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;lstm_gender&#34;</span>
version <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>
export_path <span style="color:#f92672">=</span> os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>join(MODEL_DIR, str(version))
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;export_path = {}</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#39;</span><span style="color:#f92672">.</span>format(export_path))

tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>models<span style="color:#f92672">.</span>save_model(
    model,
    export_path,
    overwrite<span style="color:#f92672">=</span>True,
    include_optimizer<span style="color:#f92672">=</span>True,
    save_format<span style="color:#f92672">=</span>None,
    signatures<span style="color:#f92672">=</span>None,
    options<span style="color:#f92672">=</span>None
)

<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">Saved model:&#39;</span>)
<span style="color:#960050;background-color:#1e0010">!</span>ls <span style="color:#f92672">-</span>l {export_path}
</code></pre></div><p>it will produce:</p>
<pre><code>export_path = lstm_gender/1

INFO:tensorflow:Assets written to: lstm_gender/1/assets

Saved model:
total 632
drwxr-xr-x 2 root root   4096 Sep 27 15:31 assets
-rw-r--r-- 1 root root 637555 Sep 27 15:31 saved_model.pb
drwxr-xr-x 2 root root   4096 Sep 27 15:31 variables
</code></pre><p>all of those files and folder under <code>1</code> directory is our exported model, you then can download to your local directory, later we will copy to our tensorflow docker.</p>
<h3 id="tensorflow-serving-with-docker">Tensorflow Serving with Docker</h3>
<p>first we create new <code>TFServing</code> directory for docker and add <code>Dockerfile</code>, <code>docker-compose.yml</code> file and <code>models.conf</code> like this tree</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">Kinaras-MBP:TFServing kinara$ tree
.
├── Dockerfile
├── docker-compose.yml
└── modeldir
    ├── models.conf
    └── tf-gender-prediction-model
        └── <span style="color:#ae81ff">1</span>
            ├── assets
            ├── saved_model.pb
            └── variables
                ├── variables.data-00000-of-00001
                └── variables.index
</code></pre></div><p>first for Dockerfile you put</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">FROM tensorflow/serving:1.14.0-rc0
</code></pre></div><p>docker-compose.yml</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">version: <span style="color:#e6db74">&#39;3&#39;</span>
services:
  tfserving:
    container_name: <span style="color:#e6db74">&#39;whale_tf_serving&#39;</span>
    restart: <span style="color:#e6db74">&#39;always&#39;</span>
    build: .
    volumes:
      - ./modeldir:/models <span style="color:#75715e"># set shared volume here</span>
    ports:
      - 8501:8501
      - 9000:9000
    command: <span style="color:#f92672">[</span><span style="color:#e6db74">&#34;tensorflow_model_server&#34;</span>, <span style="color:#e6db74">&#34;--model_config_file=/models/models.conf&#34;</span><span style="color:#f92672">]</span> <span style="color:#75715e"># we set model config file here in /models/models.conf</span>
</code></pre></div><p>models.conf</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">model_config_list: <span style="color:#f92672">{</span>
  config: <span style="color:#f92672">{</span>
    name: <span style="color:#e6db74">&#34;gender_model&#34;</span>, <span style="color:#75715e"># this we defined our model name</span>
    base_path: <span style="color:#e6db74">&#34;/models/tf-gender-prediction-model&#34;</span>, <span style="color:#75715e"># this we place our exported model directory</span>
    model_platform: <span style="color:#e6db74">&#34;tensorflow&#34;</span>
  <span style="color:#f92672">}</span>
<span style="color:#f92672">}</span>
</code></pre></div><p>as you can see from above directory tree, you put your exported model under <code>TFServing/modeldir/tf-gender-prediction-model/</code> directory</p>
<p>thats it, to run the docker container, we can use docker-compose up command</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">docker-compose up
</code></pre></div><p>if this console output already appear then your model are ready to rock and roll</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">whale_tf_serving | 2020-10-01 07:11:46.623913: I tensorflow_serving/model_servers/server.cc:324<span style="color:#f92672">]</span> Running gRPC ModelServer at 0.0.0.0:8500 ...
whale_tf_serving | <span style="color:#f92672">[</span>warn<span style="color:#f92672">]</span> getaddrinfo: address family <span style="color:#66d9ef">for</span> nodename not supported
whale_tf_serving | <span style="color:#f92672">[</span>evhttp_server.cc : 239<span style="color:#f92672">]</span> RAW: Entering the event loop ...
whale_tf_serving | 2020-10-01 07:11:46.627376: I tensorflow_serving/model_servers/server.cc:344<span style="color:#f92672">]</span> Exporting HTTP/REST API at:localhost:8501 ...
</code></pre></div><h3 id="testing-and-making-query-prediction">Testing and Making Query Prediction</h3>
<p>to make a query prediction, we could use REST api method, just like any other API call, but first we need to prepare our payload, encode our input with dictionary we exported before.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> json
<span style="color:#f92672">import</span> requests
<span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#f92672">from</span> tensorflow.keras.preprocessing.sequence <span style="color:#f92672">import</span> pad_sequences

<span style="color:#75715e"># open character dictionary from trained model before</span>
<span style="color:#66d9ef">with</span> open(<span style="color:#e6db74">&#34;char_dictionary.json&#34;</span>, <span style="color:#e6db74">&#34;r&#34;</span>) <span style="color:#66d9ef">as</span> f:
    vocab_index <span style="color:#f92672">=</span> json<span style="color:#f92672">.</span>loads(f<span style="color:#f92672">.</span>read())

name <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;Susi Susanti&#34;</span>
name <span style="color:#f92672">=</span> list(name<span style="color:#f92672">.</span>lower())
test_dt <span style="color:#f92672">=</span> [vocab_index[x] <span style="color:#66d9ef">for</span> x <span style="color:#f92672">in</span> name]
test_dt <span style="color:#f92672">=</span> pad_sequences([test_dt], maxlen<span style="color:#f92672">=</span><span style="color:#ae81ff">32</span>)

payload <span style="color:#f92672">=</span> {
    <span style="color:#e6db74">&#34;signature_name&#34;</span>: <span style="color:#e6db74">&#34;serving_default&#34;</span>, 
    <span style="color:#e6db74">&#34;instances&#34;</span>: test_dt<span style="color:#f92672">.</span>tolist()
}

headers <span style="color:#f92672">=</span> {<span style="color:#e6db74">&#34;content-type&#34;</span>: <span style="color:#e6db74">&#34;application/json&#34;</span>}
resp <span style="color:#f92672">=</span> requests<span style="color:#f92672">.</span>post(<span style="color:#e6db74">&#39;http://&lt;your local machine ip address&gt;:8501/v1/models/gender_model:predict&#39;</span>, data<span style="color:#f92672">=</span>json<span style="color:#f92672">.</span>dumps(payload), headers<span style="color:#f92672">=</span>headers)
prediction <span style="color:#f92672">=</span> json<span style="color:#f92672">.</span>loads(resp<span style="color:#f92672">.</span>text)[<span style="color:#e6db74">&#39;predictions&#39;</span>][<span style="color:#ae81ff">0</span>]

<span style="color:#66d9ef">if</span> np<span style="color:#f92672">.</span>argmax(prediction) <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span>:
    <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;Female with confidence score: {:.2f}%&#39;</span><span style="color:#f92672">.</span>format(prediction[<span style="color:#ae81ff">0</span>] <span style="color:#f92672">*</span> <span style="color:#ae81ff">100</span>))
<span style="color:#66d9ef">elif</span> np<span style="color:#f92672">.</span>argmax(prediction) <span style="color:#f92672">==</span> <span style="color:#ae81ff">1</span>:
    <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;Male with confidence score: {:.2f}%&#39;</span><span style="color:#f92672">.</span>format(prediction[<span style="color:#ae81ff">1</span>] <span style="color:#f92672">*</span> <span style="color:#ae81ff">100</span>))

<span style="color:#75715e">## sample output</span>
<span style="color:#75715e">## name: &#34;Susi Susanti&#34;</span>
<span style="color:#75715e">## Female with confidence score: 82.21%</span>

<span style="color:#75715e">## name: &#34;Sudjiwo Tedjo&#34;</span>
<span style="color:#75715e">## Male with confidence score: 99.93%</span>
</code></pre></div><p>Congratulation, you just have had your model deployed into production level and ready to handle queries from other applications or users.</p>
<p>In summary, we can deploy our deep learning model trained with tensorflow model with Tensorflow Serving, Tensorflow Serving provide best feature for serving model with efficient performance, multi versions and also support multi models serving. Other applications can access our model with REST API call or gRCP for asking prediction.</p>
<p>This is the end of the second part of our series about developing and deploying deep learning model the repo also had been updated <a href="https://github.com/yudanta/lstm-gender-classification,">https://github.com/yudanta/lstm-gender-classification,</a> if you haven&rsquo;t read the first post about how to train the model you can visit this page: <a href="https://yudanta.github.io/posts/series-1-lstm-gender-classification-tensorflow/">https://yudanta.github.io/posts/series-1-lstm-gender-classification-tensorflow/</a></p>
<p>for the next post, will be add an alternative ways to serving our deep learning model with Flask, Thank you&hellip; stay tune&hellip;</p>

    </section>
</article>

<footer id="post-meta" class="clearfix">
    
    <img class="avatar" src="https://yudanta.github.io/images/avatar.png">
    <div>
        <span class="dark">Yudanta</span>
        <span>Developer, Data Processing, Natural Language Processing, and everything in between.</span>
    </div>
    
    <section id="sharing">
        <a class="twitter" href="https://twitter.com/intent/tweet?text=https%3a%2f%2fyudanta.github.io%2fposts%2fseries-2-exporting-lstm-gender-classification-and-serving-with-tensorflowserving%2f - Series%202%20Exporting%20LSTM%20Gender%20Classification%20and%20Serving%20With%20Tensorflowserving "><span class="icon-twitter"> tweet</span></a>

<a class="facebook" href="#" onclick="
    window.open(
      'https://www.facebook.com/sharer/sharer.php?u='+encodeURIComponent(location.href),
      'facebook-share-dialog',
      'width=626,height=436');
    return false;"><span class="icon-facebook-rect"> Share</span>
</a>

    </section>
</footer>

<div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "yudanta-github-io" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

<ul id="post-list" class="archive readmore">
    <h3>Read more</h3>

    
    
    
        <li>
            <a href="/posts/series-1-lstm-gender-classification-tensorflow/">Series 1 LSTM Gender Classification Tensorflow<aside class="dates">Sep 27 2020</aside></a>
        </li>
    
        <li>
            <a href="/posts/simple-asymetric-encryption-with-python/">Simple Asymetric Encryption With Python<aside class="dates">Sep 14 2020</aside></a>
        </li>
    
        <li>
            <a href="/posts/nvidia-docker-and-docker-compose-enabled/">Nvidia Docker and Docker Compose Enabled<aside class="dates">Jan 11 2019</aside></a>
        </li>
    
        <li>
            <a href="/posts/flask-mongoengine-multiple-databases-with-alias/">Flask Mongoengine, Multiple Databases With Alias<aside class="dates">Jan 11 2019</aside></a>
        </li>
    
        <li>
            <a href="/posts/how-i-dockerize-my-flask-app-with-pypy-and-supervisord/">How I Dockerize My Flask App With Pypy and Supervisord<aside class="dates">Dec 19 2018</aside></a>
        </li>
    
        <li>
            <a href="/posts/the-books-i-read-recently/">The Books I Read Recently<aside class="dates">Dec 18 2018</aside></a>
        </li>
    
        <li>
            <a href="/posts/hello-world/">Hello World<aside class="dates">Dec 15 2018</aside></a>
        </li>
    
</ul>



        <footer id="footer">
    
        <div id="social">

	
	
    
    <a class="symbol" href="https://github.com/yudanta/">
        github
    </a>
    
    <a class="symbol" href="https://linkedin.com/in/yudanta/">
        linkedin
    </a>
    
    <a class="symbol" href="https://twitter.com/akuyudanta/">
        twitterbird
    </a>
    


</div>

    
    <p class="small">
    
        © Copyright 2020 Yudanta
    
    </p>
</footer>

    </section>
    <script src="//ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js"></script>
<script src="https://yudanta.github.io/js/main.js"></script>
<script src="https://yudanta.github.io/js/highlight.js"></script>
<script>hljs.initHighlightingOnLoad();</script>




<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-45000886-2', 'auto');
	
	ga('send', 'pageview');
}
</script>


</body>
</html>
